model: resnet101_attention
outputpath: experiments/4

dataset_base_path: /lustre/home/acct-stu/stu168/data/image_captioning/flickr8k
vocab_path: utils/vocab_set.pkl
embedding_dim: 300
attention_dim: 256
decoder_size: 256
sample_method: beam # 'greed' or 'beam'
train_args:
    batch_size: 32
    learning_rate: !!float 1e-3
    num_epochs: 45
    save_freq: 10
    start_eps: 1
    decay_eps: 0.03
eval_args:
    batch_size: 1